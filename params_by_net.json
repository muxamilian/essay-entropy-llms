{"mistral": 7240000000,
"tinyllama": 1100000000,
"gpt": 137000000,
"gpt_large": 812000000,
"gpt_xl": 1610000000,
"gemma-2B": 2510000000,
"opt-125M": 125000000,
"opt-2.7B": 2700000000,
"gemma-7B": 8540000000}