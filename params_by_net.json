{"mistral-7B": 7240000000,
"tinyllama": 1100000000,
"gpt2": 137000000,
"gpt2-large": 812000000,
"gpt2-xl": 1610000000,
"gemma-2B": 2510000000,
"opt-125M": 125000000,
"opt-2.7B": 2700000000,
"gemma-7B": 8540000000}